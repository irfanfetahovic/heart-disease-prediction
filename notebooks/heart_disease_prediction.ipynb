{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0af687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "\n",
    "import os\n",
    "\n",
    "# Exploratory data analysis (EDA) and plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure plots appear in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "## Machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras import Model, Input \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# Column transformations\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "## Model evaluation tools\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import RocCurveDisplay, roc_auc_score\n",
    "\n",
    "\n",
    "# Print last updated timestamp\n",
    "import time\n",
    "print(f\"Last updated: {time.asctime()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4e3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCI heart disease dataset from Kaggle https://www.kaggle.com/datasets/sumaiyatasmeem/heart-disease-classification-dataset\n",
    "\n",
    "# load file\n",
    "df = pd.read_csv(\"../data/heart_disease_classification_dataset.csv\")\n",
    "df = df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "# df.shape\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d998c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of positive (1) and negative (0) samples in our dataset\n",
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0324f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized value counts\n",
    "df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ffb706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of missing values per column\n",
    "missing_per_column = df.isna().sum()\n",
    "print(missing_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a9561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a8ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CLEAN AND CONVERT DATA AND COLUMN TYPES\n",
    "\n",
    "# Simple encoding of the categorical variables (applicable to variables with two values, like those below)\n",
    "df['sex'] = df['sex'].map({'female':0, 'male':1})\n",
    "df['target'] = df['target'].map({'no':0, 'yes':1})\n",
    "\n",
    "# Initial handling of the missing values\n",
    "df = df.replace({None: np.nan, '': np.nan, '?': np.nan})  # optional: convert None, blank or ? strings to NaN\n",
    "df = df.fillna(np.nan)  # ensures any remaining missing values are np.nan\n",
    "\n",
    "num_cols = df.select_dtypes(include=[np.number, 'int64', 'float64']).columns\n",
    "print(\"Numeric columns before cleaning:\", num_cols)\n",
    "cat_cols = df.select_dtypes(include=['category', 'object']).columns\n",
    "print(\"Categorical columns before cleaning:\", cat_cols)\n",
    "date_cols = list(df.select_dtypes(include=['datetime64']).columns)\n",
    "print(\"Date columns before cleaning:\", date_cols)\n",
    "\n",
    "\n",
    "# # Replace '?' with NaN and convert to numeric (example)\n",
    "# df['column'] = df['column'].replace('?', np.nan)\n",
    "# df['column'] = pd.to_numeric(df['column'], errors='coerce')\n",
    "\n",
    "\n",
    "# # CHECK DATA TYPES AFTER CLEANING (reports if any column has mixed types)\n",
    "# for col in df.columns: \n",
    "#     types = df[col].map(type).unique() \n",
    "#     if len(types) > 1: \n",
    "#         print(col, types)\n",
    "\n",
    "\n",
    "# print(df['thalach'].map(type).unique()) # see all data types in target column\n",
    "# print(df['thalach'].unique())  # see all distinct values\n",
    "# print(df['thalach'].dtype) # check data type of target column\n",
    "\n",
    "# CONVERT SOME NUMERICAL COLUMNS TO CATEGORICAL (BASED ON THEIR VALUES)\n",
    "df['sex'] = df['sex'].astype('category')\n",
    "df['cp'] = df['cp'].astype('category')\n",
    "df['fbs'] = df['fbs'].astype('category')\n",
    "df['restecg'] = df['restecg'].astype('category')\n",
    "df['exang'] = df['exang'].astype('category')\n",
    "df['slope'] = df['slope'].astype('category')\n",
    "df['ca'] = df['ca'].astype('category')\n",
    "df['thal'] = df['thal'].astype('category')\n",
    "\n",
    "\n",
    "# # CONVERT DATE-LIKE COLUMNS TO DATE COLUMNS\n",
    "# for col in df.columns:\n",
    "#     # Only check object or string columns\n",
    "#     if df[col].dtype == 'object' or pd.api.types.is_string_dtype(df[col]):\n",
    "#         parsed = pd.to_datetime(df[col], errors='coerce')\n",
    "#         # If most of the column is valid dates, convert it\n",
    "#         if parsed.notna().mean() > 0.8:  # adjust threshold if needed\n",
    "#             df[col] = parsed\n",
    "\n",
    "\n",
    "\n",
    "# #CONVERT NUMERIC COLUMNS WITH LOW UNIQUE VALUES TO CATEGORICAL\n",
    "# num_cols = df.select_dtypes(include=[np.number, 'int64', 'float64']).columns\n",
    "# print(\"Numeric columns:\", num_cols)\n",
    "# cat_cols = df.select_dtypes(include=['category', 'object']).columns\n",
    "# print(\"Categorical columns:\", cat_cols)\n",
    "# numeric_like_categorical = []\n",
    "# for col in num_cols:\n",
    "#     print(col, df[col].nunique())\n",
    "#     if df[col].nunique() <= 6:\n",
    "#         numeric_like_categorical.append(col)\n",
    "# print(\"Numeric-like categorical columns:\", numeric_like_categorical)\n",
    "# for col in numeric_like_categorical:\n",
    "#     df[col] = df[col].astype('category')\n",
    "#     # df[col] = df[col].cat.add_categories([-1]).fillna(-1)  # Handle missing values in categorical columns without Imputer\n",
    "#     # df[col] = df[col].astype(str).fillna('missing').astype('category') # alternative way to handle missing values in categorical columns without Imputer\n",
    "\n",
    "\n",
    "#PRINT COLUMNS BY DATA TYPE\n",
    "num_cols = df.select_dtypes(include=[np.number, 'int64', 'float64']).columns\n",
    "cat_cols = df.select_dtypes(include=['category', 'object']).columns\n",
    "date_cols = df.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, UTC]']).columns\n",
    "print(\"Numeric columns after cleaning and conversion:\", num_cols)\n",
    "print(\"Categorical columns after cleaning and conversion:\", cat_cols) \n",
    "print(\"Date columns:\", date_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2555c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING DISTRIBUTION OF TARGET VALUES\n",
    "\n",
    "#df.target.value_counts().plot(kind=\"bar\", color=[\"salmon\", \"lightblue\"]);\n",
    "sns.barplot(x=df.target.value_counts().index, y=df.target.value_counts().values, palette=[\"salmon\", \"lightblue\"]);\n",
    "plt.xlabel(\"Target (0 = No Disease, 1 = Disease)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Heart Disease in Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5002ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b586183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4962c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSSTAB TABLE - HEART DISEASE BY SEX\n",
    "\n",
    "ct = pd.crosstab(df.target, df.sex)\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5adc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING HEART DISEASE BY SEX\n",
    "\n",
    "ct.plot(kind='bar')\n",
    "plt.title('Heart Disease by Sex')\n",
    "plt.xlabel('Sex (0=Female, 1=Male)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(['No Disease', 'Disease'])\n",
    "plt.show()\n",
    "\n",
    "# # Alternative visualization using seaborn\n",
    "# sns.countplot(data=df, x='target', hue='sex')\n",
    "# plt.xlabel('Heart Disease Status')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Heart Disease by Sex')\n",
    "# plt.legend(title='Sex', labels=['Female', 'Male'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcacbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING AGE VS CHOLESTEROL BY HEART DISEASE STATUS\n",
    "\n",
    "sns.scatterplot(x=df.age, y=df.chol, hue=df.target)\n",
    "plt.title('Age vs Cholesterol by Heart Disease Status')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Cholesterol Level')\n",
    "plt.legend(['No Disease', 'Disease'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff17eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING HEART DISEASE BY CHEST PAIN TYPE\n",
    "\n",
    "sns.countplot(data=df, x='cp', hue='target')\n",
    "plt.xlabel('Chest Pain Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Heart Disease by Chest Pain Type')\n",
    "plt.legend(title='Heart Disease Status', labels=['No Disease', 'Disease'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd5aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRELATION HEATMAP FOR NUMERIC FEATURES\n",
    "\n",
    "if len(num_cols) > 1:\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.heatmap(df[num_cols].corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Numeric Feature Correlation')\n",
    "    plt.show()\n",
    "\n",
    "# Alternative\n",
    "# corr_matrix = df.corr()\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# sns.heatmap(corr_matrix, \n",
    "#             annot=True, \n",
    "#             linewidths=0.5, \n",
    "#             fmt= \".2f\", \n",
    "#             cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e2171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE DUPLICATES\n",
    "\n",
    "initial_count = df.shape[0]\n",
    "df = df.drop_duplicates()\n",
    "print(f\"\\nRemoved {initial_count - df.shape[0]} duplicate rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd6355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DETECT & REMOVE OUTLIERS\n",
    "\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.stats import zscore\n",
    "\n",
    "# def remove_outliers(df, method='zscore', threshold=3, show_plots=False):\n",
    "#     numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "#     if len(numeric_cols) == 0:\n",
    "#         print(\"No numeric columns found.\")\n",
    "#         return df\n",
    "\n",
    "#     print(\"Numeric columns for outlier detection:\", list(numeric_cols))\n",
    "\n",
    "#     # Optional boxplots\n",
    "#     if show_plots:\n",
    "#         for col in numeric_cols:\n",
    "#             plt.figure()\n",
    "#             sns.boxplot(x=df[col])\n",
    "#             plt.title(f'Boxplot: {col}')\n",
    "#             plt.show()\n",
    "\n",
    "#     n_rows_before = len(df)  # store original number of rows\n",
    "\n",
    "#     if method == 'zscore':\n",
    "#         # Ensure output is always 2D NumPy array\n",
    "#         z = np.abs(zscore(df[numeric_cols].to_numpy(), nan_policy='omit'))\n",
    "#         outlier_mask = (z > threshold)\n",
    "#         for i, col in enumerate(numeric_cols):\n",
    "#             num_outliers = outlier_mask[:, i].sum()\n",
    "#             print(f\"{col}: {num_outliers} outliers ({num_outliers / n_rows_before * 100:.2f}%)\")\n",
    "\n",
    "#         # Keep only rows without any outlier\n",
    "#         df = df[(z < threshold).all(axis=1)]\n",
    "\n",
    "#     elif method == 'iqr':\n",
    "#         for col in numeric_cols:\n",
    "#             Q1 = df[col].quantile(0.25)\n",
    "#             Q3 = df[col].quantile(0.75)\n",
    "#             IQR = Q3 - Q1\n",
    "#             mask = (df[col] >= Q1 - 1.5 * IQR) & (df[col] <= Q3 + 1.5 * IQR)\n",
    "#             num_outliers = (~mask).sum()\n",
    "#             print(f\"{col}: {num_outliers} outliers ({num_outliers / n_rows_before * 100:.2f}%)\")\n",
    "#             df = df[mask]\n",
    "\n",
    "#     n_rows_after = len(df)\n",
    "#     print(f\"\\nTotal rows removed: {n_rows_before - n_rows_after} ({(n_rows_before - n_rows_after) / n_rows_before * 100:.2f}%)\")\n",
    "#     print(\"Outliers handled.\\n\")\n",
    "#     return df\n",
    "# #df = remove_outliers(df, method='zscore', threshold=3, show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DATE/TIME FEATURE EXTRACTION\n",
    "\n",
    "# def extract_date_features(df, date_cols):\n",
    "#     for col in date_cols:\n",
    "#         df[col+'_year'] = df[col].dt.year\n",
    "#         df[col+'_month'] = df[col].dt.month\n",
    "#         df[col+'_day'] = df[col].dt.day\n",
    "#         df[col+'_weekday'] = df[col].dt.weekday\n",
    "#         df[col+'_week'] = df[col].dt.isocalendar().week\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HANDLE SKEWNESS IN NUMERIC FEATURES\n",
    "\n",
    "# def handle_skewness(df, threshold=0.75, method='yeo-johnson'):\n",
    "#     numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "#     skewed_feats = df[numeric_cols].apply(lambda x: skew(x.dropna()))\n",
    "#     skewed_feats = skewed_feats[abs(skewed_feats) > threshold].index\n",
    "#     pt = PowerTransformer(method=method)\n",
    "#     if len(skewed_feats) > 0:\n",
    "#         df[skewed_feats] = pt.fit_transform(df[skewed_feats])\n",
    "#         print(f\"\\nTransformed skewed numeric features: {list(skewed_feats)}\")\n",
    "#     else:\n",
    "#         print(\"\\nNo skewed numeric features detected.\")\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c71d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CORRELATION-BASED FEATURE SELECTION\n",
    "\n",
    "# def remove_high_corr_features(df, threshold=0.9):\n",
    "#     numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "#     corr_matrix = df[numeric_cols].corr().abs()\n",
    "#     upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "#     to_drop = [col for col in upper.columns if any(upper[col] > threshold)]\n",
    "#     df = df.drop(columns=to_drop)\n",
    "#     if to_drop:\n",
    "#         print(f\"\\nRemoved highly correlated features: {to_drop}\")\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445680cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOW VARIANCE FEATURE REMOVAL\n",
    "\n",
    "# def remove_low_variance(df, threshold=0.01):\n",
    "#     selector = VarianceThreshold(threshold)\n",
    "#     numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "#     selector.fit(df[numeric_cols])\n",
    "#     low_var_cols = numeric_cols[~selector.get_support()]\n",
    "#     df = df.drop(columns=low_var_cols)\n",
    "#     if len(low_var_cols) > 0:\n",
    "#         print(f\"\\nRemoved low variance features: {list(low_var_cols)}\")\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e7fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b030b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPARATION - CREATING FEATURES AND TARGET VARIABLE, CONVERTING TO NUMPY, GETTING NUMERICAL AND CATEGORICAL COLUMNS, AND THEIR INDICES\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(\"target\", axis=1).to_numpy()  # Feature matrix\n",
    "y = df[\"target\"].to_numpy()  # Select target variable and convert to np.array\n",
    "#y = df.target.values # alternative way to convert to np.array\n",
    "\n",
    "# Identify numeric and categorical columns and their indices\n",
    "df = df.drop(columns=['target'], errors='ignore')\n",
    "num_cols = df.select_dtypes(include=[np.number, 'int64', 'float64']).columns\n",
    "cat_cols = df.select_dtypes(include=['category', 'object']).columns\n",
    "print(\"Numeric columns:\", num_cols)\n",
    "print(\"Categorical columns:\", cat_cols) \n",
    "# Define column indices\n",
    "num_cols_idx = df.columns.get_indexer(num_cols)\n",
    "cat_cols_idx = df.columns.get_indexer(cat_cols)\n",
    "print(\"Numeric column indices:\", num_cols_idx)\n",
    "print(\"Categorical column indices:\", cat_cols_idx) \n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Target vector shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93874ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTING INTO TRAINING AND TEST DATA, AND TRANSFORMING DATA\n",
    "\n",
    "def split_transform_data(X, y, test_size=0.2, num_cols_idx=num_cols_idx, cat_cols_idx=cat_cols_idx):\n",
    "    \"\"\"\n",
    "    Splits the data into training and testing sets, applies imputation and encoding.\n",
    "    \n",
    "    Parameters:\n",
    "    X : np.array\n",
    "        Feature matrix.\n",
    "    y : np.array\n",
    "        Target vector.\n",
    "    test_size : float\n",
    "        Proportion of the dataset to include in the test split.\n",
    "    num_cols_idx : list\n",
    "        Indices of numeric columns\n",
    "    cat_cols_idx : list\n",
    "        Indices of categorical columns\n",
    "    \"\"\"\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Apply SimpleImputer to numeric columns\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train[:,num_cols_idx] = imputer.fit_transform(X_train[:,num_cols_idx])\n",
    "    X_test[:,num_cols_idx]  = imputer.transform(X_test[:,num_cols_idx])\n",
    "\n",
    "    # Apply SimpleImputer to categorical columns\n",
    "    imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "    if len(cat_cols_idx) > 0:\n",
    "        X_train[:,cat_cols_idx] = imputer_cat.fit_transform(X_train[:,cat_cols_idx])\n",
    "        X_test[:,cat_cols_idx]  = imputer_cat.transform(X_test[:,cat_cols_idx])\n",
    "\n",
    "    # Apply feature scaling to selected (true) numerical columns\n",
    "    sc = StandardScaler()\n",
    "    X_train[:,num_cols_idx] = sc.fit_transform(X_train[:,num_cols_idx])\n",
    "    X_test[:,num_cols_idx] = sc.transform(X_test[:,num_cols_idx])\n",
    "\n",
    "    # Apply OneHotEncoder to categorical columns\n",
    "    ct = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'), cat_cols_idx)\n",
    "            ],\n",
    "            remainder='passthrough'  # Keep non-specified columns as they are\n",
    "        )\n",
    "    \n",
    "\n",
    "    X_train = ct.fit_transform(X_train)\n",
    "    X_test = ct.transform(X_test)\n",
    "\n",
    "    # Creating LabelEncoder - optional\n",
    "    le = LabelEncoder()\n",
    "    # y_train = le.fit_transform(y_train)\n",
    "    # y_test  = le.transform(y_test)\n",
    "    return X_train, X_test, y_train, y_test, imputer, imputer_cat, sc, ct, le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae0193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Detailed model evaluation for the Logistic Regression model (similar approach can be used for other models)\n",
    "\n",
    "# # Identify numeric and categorical columns and their indices\n",
    "# dfc = df.copy().drop(columns=['target'], errors='ignore')\n",
    "# num_cols = dfc.select_dtypes(include=[np.number, 'int64', 'float64']).columns\n",
    "# cat_cols = dfc.select_dtypes(include=['category', 'object']).columns\n",
    "# print(\"Numeric columns:\", num_cols)\n",
    "# print(\"Categorical columns:\", cat_cols) \n",
    "# # Define column indices\n",
    "# num_cols_idx = dfc.columns.get_indexer(num_cols)\n",
    "# cat_cols_idx = dfc.columns.get_indexer(cat_cols)\n",
    "# print(\"Numeric column indices:\", num_cols_idx)\n",
    "# print(\"Categorical column indices:\", cat_cols_idx) \n",
    "\n",
    "# # Separate features and target variable\n",
    "# X = df.drop(\"target\", axis=1).to_numpy()  # Feature matrix\n",
    "# y = df[\"target\"].to_numpy()  # Select target variable and convert to np.array\n",
    "# #y = df.target.values # alternative way to convert to np.array\n",
    "\n",
    "# print(\"Feature matrix shape:\", X.shape)\n",
    "# print(\"Target vector shape:\", y.shape)\n",
    "\n",
    "# def split_transform_data(X, y, test_size=0.2, num_cols_idx=num_cols_idx, cat_cols_idx=cat_cols_idx):\n",
    "#     \"\"\"\n",
    "#     Splits the data into training and testing sets, applies imputation and encoding.\n",
    "    \n",
    "#     Parameters:\n",
    "#     X : np.array\n",
    "#         Feature matrix.\n",
    "#     y : np.array\n",
    "#         Target vector.\n",
    "#     test_size : float\n",
    "#         Proportion of the dataset to include in the test split.\n",
    "#     num_cols_idx : list\n",
    "#         Indices of numeric columns\n",
    "#     cat_cols_idx : list\n",
    "#         Indices of categorical columns\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Split data into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Apply SimpleImputer to numeric columns\n",
    "#     imputer = SimpleImputer(strategy='mean')\n",
    "#     X_train[:,num_cols_idx] = imputer.fit_transform(X_train[:,num_cols_idx])\n",
    "#     X_test[:,num_cols_idx]  = imputer.transform(X_test[:,num_cols_idx])\n",
    "\n",
    "#     # Apply SimpleImputer to categorical columns\n",
    "#     imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "#     if len(cat_cols_idx) > 0:\n",
    "#         X_train[:,cat_cols_idx] = imputer_cat.fit_transform(X_train[:,cat_cols_idx])\n",
    "#         X_test[:,cat_cols_idx]  = imputer_cat.transform(X_test[:,cat_cols_idx])\n",
    "\n",
    "#     # Apply feature scaling to numerical columns\n",
    "#     sc = StandardScaler()\n",
    "#     X_train[:,num_cols_idx] = sc.fit_transform(X_train[:,num_cols_idx])\n",
    "#     X_test[:,num_cols_idx] = sc.transform(X_test[:,num_cols_idx])\n",
    "\n",
    "#     # Apply OneHotEncoder to categorical columns\n",
    "#     ct = ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             ('onehot', OneHotEncoder(handle_unknown='ignore'), cat_cols_idx)\n",
    "#             ],\n",
    "#             remainder='passthrough'  # Keep non-specified columns as they are\n",
    "#         )\n",
    "\n",
    "#     X_train = ct.fit_transform(X_train)\n",
    "#     X_test = ct.transform(X_test)\n",
    "\n",
    "#     le = LabelEncoder()\n",
    "#     y_train = le.fit_transform(y_train)\n",
    "#     y_test  = le.transform(y_test)\n",
    "#     return X_train, X_test, y_train, y_test, imputer, imputer_cat, sc, ct, le\n",
    "\n",
    "\n",
    "\n",
    "# # Logistic Regression\n",
    "\n",
    "\n",
    "# # No CV\n",
    "\n",
    "# X_train, X_test, y_train, y_test, imputer, imputer_cat, sc, ct, le = split_transform_data(X, y, test_size=0.2, num_cols_idx=num_cols_idx, cat_cols_idx=cat_cols_idx)\n",
    "\n",
    "\n",
    "# classifier = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_train = classifier.predict(X_train)\n",
    "# acc = accuracy_score(y_train, y_pred_train)\n",
    "# #acc = classifier.score(X_train, y_train)\n",
    "# print(\"Train Accuracy:\", acc)\n",
    "\n",
    "\n",
    "# y_pred_test = classifier.predict(X_test)\n",
    "# acc = accuracy_score(y_test, y_pred_test)\n",
    "# print(\"Test Accuracy:\", acc)\n",
    "\n",
    "# # With CV\n",
    "\n",
    "# X_trainval, X_test, y_trainval, y_test, imputer, imputer_cat, sc, ct, le = split_transform_data(X, y, test_size=0.2, num_cols_idx=num_cols_idx, cat_cols_idx=cat_cols_idx)\n",
    "\n",
    "# classifier = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# scoring = ['accuracy', 'f1_macro', 'precision_macro', 'recall_macro']\n",
    "# results = cross_validate(classifier, X_trainval, y_trainval, cv=5, scoring=scoring)\n",
    "\n",
    "# for metric in scoring:\n",
    "#     print(f\"CV Train {metric.capitalize()}:\", results['test_' + metric])\n",
    "#     print(f\"CV Train {metric.capitalize()} mean:\", results['test_' + metric].mean())\n",
    "#     print(f\"CV Train {metric.capitalize()} std:\", results['test_' + metric].std())\n",
    "\n",
    "\n",
    "# # ----- Final fit on full training data\n",
    "# # This must be done because cross-validate function only provides metrics, not a trained model\n",
    "# classifier.fit(X_trainval, y_trainval)\n",
    "\n",
    "# # ----- Final evaluation on unseen test set -----\n",
    "# y_pred_test = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "# acc = accuracy_score(y_test, y_pred_test)\n",
    "# acc = classifier.score(X_test, y_test)\n",
    "# # For binary classification\n",
    "# # f1 = f1_score(y_test, y_pred_test)\n",
    "# # For multiclass classification\n",
    "# f1_macro = f1_score(y_test, y_pred_test, average='macro')  # average='micro' or 'weighted' also possible\n",
    "# precision = precision_score(y_test, y_pred_test, average='macro')\n",
    "# recall = recall_score(y_test, y_pred_test, average='macro')\n",
    "# print(\"CV Test Accuracy:\", acc)\n",
    "# print(\"CV Test F1 Macro:\", f1_macro)\n",
    "# print(\"CV Test Precision Macro:\", precision)\n",
    "# print(\"CV Test Recall Macro:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f330ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARING DIFFERENT CLASSIFIER MODELS\n",
    "\n",
    "# X_train, X_test, y_train, y_test, imputer, imputer_cat, sc, ct, le = split_transform_data(X, y, test_size=0.2, num_cols_idx=num_cols_idx, cat_cols_idx=cat_cols_idx)\n",
    "\n",
    "# models = {\"KNN\": KNeighborsClassifier(),\n",
    "#           \"Logistic Regression\": LogisticRegression(), \n",
    "#           \"Random Forest\": RandomForestClassifier(),\n",
    "#           \"XGBoost\": XGBClassifier()}\n",
    " \n",
    "# models_accuracy = {}\n",
    "# # Loop through models\n",
    "# for name, model in models.items():\n",
    "#     # Fit the model to the data\n",
    "#     model.fit(X_train, y_train)\n",
    "#     # Evaluate the model and append its score to model_scores\n",
    "#     models_accuracy[name] = model.score(X_test, y_test)\n",
    "\n",
    "# models_accuracy\n",
    "\n",
    "# Alternative approach using cross-validation (better since you dont want to use test data during model selection and tuning)\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test, imputer, imputer_cat, sc, ct, le = split_transform_data(X, y, test_size=0.2, num_cols_idx=num_cols_idx, cat_cols_idx=cat_cols_idx)\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
    "}\n",
    "\n",
    "models_accuracy = {}\n",
    "\n",
    "# Loop through models\n",
    "for name, model in models.items():\n",
    "    # Perform 5-fold cross-validation on the training data\n",
    "    cv_scores = cross_val_score(model, X_trainval, y_trainval, cv=5, scoring='accuracy')\n",
    "    # Store the mean accuracy\n",
    "    models_accuracy[name] = np.mean(cv_scores)\n",
    "\n",
    "models_accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d27889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING DATAFRAME TO DISPLAY DATA ABOUT DIFFERENT MODELS AND THEIR ACCURACY\n",
    "\n",
    "models_df = pd.DataFrame(models_accuracy, index=['accuracy'])\n",
    "models_df = models_df.T.reset_index().rename(columns={'index': 'model'})\n",
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81727f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZING DIFFERENT MODELS\n",
    "\n",
    "sns.barplot(data=models_df, x='model', y='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90bb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING AND EVALUATING NEURAL NETWORK CLASSIFIER FOR HEART DISEASE PREDICTION\n",
    "\n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(10, activation='relu', input_shape=(13,)),\n",
    "#     Dense(6, activation='relu'),\n",
    "#     Dense(3, activation='relu'),\n",
    "#     Dense(1, activation='sigmoid')  # binary output\n",
    "# ])\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "# model.fit(X_trainval, y_trainval, epochs=50, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# # Evaluate the model\n",
    "# train_loss, train_accuracy = model.evaluate(X_trainval, y_trainval, verbose=0)\n",
    "# print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Alternative approach using Functional API\n",
    "inputs = Input(shape=(30,)) \n",
    "x = Dense(10, activation='relu')(inputs) \n",
    "x = Dense(6, activation='relu')(x) \n",
    "x = Dense(3, activation='relu')(x) \n",
    "outputs = Dense(1, activation='sigmoid')(x) \n",
    "model = Model(inputs=inputs, outputs=outputs) \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "model.summary() \n",
    " \n",
    "model.fit(X_trainval, y_trainval, epochs=50, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss, train_accuracy = model.evaluate(X_trainval, y_trainval, verbose=0)\n",
    "print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b24cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "# HYPERPARAMETER TUNING FOR XGB ALGORITHM\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters to tune\n",
    "    param = {\n",
    "    'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "    'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "    'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
    "    'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 5.0),\n",
    "    'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 5.0),\n",
    "    'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 10.0),\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "   \n",
    "    # Create and train model\n",
    "    model = XGBClassifier(**param)\n",
    "    score = cross_val_score(model, X_trainval, y_trainval, cv=3, scoring='accuracy').mean()\n",
    "    return score  # Optuna will try to maximize this\n",
    "\n",
    "# Create a study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Accuracy: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Creating final model with the best hyperparameters\n",
    "best_model_xgb = XGBClassifier(**trial.params, eval_metric='logloss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETER TUNING FOR LOGISTIC REGRESSION ALGORITHM\n",
    "\n",
    "import optuna\n",
    "\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test, imputer, imputer_cat, sc, ct, le = split_transform_data(X, y, test_size=0.2, num_cols_idx=num_cols_idx, cat_cols_idx=cat_cols_idx)\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    # Define all valid (penalty, solver) combinations\n",
    "    valid_combinations = [\n",
    "        ('l1', 'liblinear'), \n",
    "        ('l1', 'saga'),\n",
    "        ('l2', 'lbfgs'), \n",
    "        ('l2', 'liblinear'), \n",
    "        ('l2', 'sag'), \n",
    "        ('l2', 'saga'), \n",
    "        ('l2', 'newton-cg'),\n",
    "        ('elasticnet', 'saga'),\n",
    "        (None, 'lbfgs'), \n",
    "        (None, 'newton-cg'), \n",
    "        (None, 'sag'), \n",
    "        (None, 'saga')\n",
    "    ]\n",
    "\n",
    "    # Sample one valid combination\n",
    "    penalty, solver = trial.suggest_categorical('combo', valid_combinations)\n",
    "\n",
    "    # Only set l1_ratio if penalty is elasticnet\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0.0, 1.0) if penalty == 'elasticnet' else None\n",
    "\n",
    "    # Regularization strength\n",
    "    C = trial.suggest_float('C', 0.001, 100.0, log=True)\n",
    "\n",
    "    # Create Logistic Regression model\n",
    "    model = LogisticRegression(\n",
    "        penalty=penalty,\n",
    "        solver=solver,\n",
    "        C=C,\n",
    "        l1_ratio=l1_ratio,\n",
    "        max_iter=1000\n",
    "    )\n",
    "\n",
    "    # Evaluate using cross-validation\n",
    "    score = cross_val_score(model, X_trainval, y_trainval, cv=5, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "# Create study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "# Print best hyperparameters\n",
    "trial = study.best_trial\n",
    "print(\"Best trial:\")\n",
    "print(f\"  Accuracy: {trial.value}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Extract penalty and solver from the 'combo' tuple\n",
    "best_penalty, best_solver = trial.params['combo']\n",
    "best_l1_ratio = trial.params.get('l1_ratio', None)\n",
    "best_C = trial.params['C']\n",
    "\n",
    "# Create final Logistic Regression model with the best hyperparameters\n",
    "best_model_lr = LogisticRegression(\n",
    "    penalty=best_penalty,\n",
    "    solver=best_solver,\n",
    "    C=best_C,\n",
    "    l1_ratio=best_l1_ratio,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATING AND COMPARING TWO BEST MODELS TO SELECT THE BETTER ONE\n",
    "\n",
    "models = {\n",
    "    \"XGBoost\": best_model_xgb,\n",
    "    \"Logistic Regression\": best_model_lr\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_trainval, y_trainval, cv=5, scoring='accuracy')\n",
    "    cv_results[name] = {\n",
    "        \"mean_accuracy\": np.mean(scores),\n",
    "        \"std_accuracy\": np.std(scores)\n",
    "    }\n",
    "\n",
    "for model_name, results in cv_results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Mean Accuracy: {results['mean_accuracy']:.4f}\")\n",
    "    print(f\"  Std Accuracy: {results['std_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING AND TESTING THE BEST SELECTED MODEL (WHICH IS LOGISTIC REGRESSION)\n",
    "\n",
    "best_model_lr.fit(X_trainval, y_trainval)\n",
    "y_pred_test = best_model_lr.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy:\", acc)\n",
    "f1_score = f1_score(y_test, y_pred_test)\n",
    "print(\"Test F1 Score:\", f1_score)\n",
    "precision_score = precision_score(y_test, y_pred_test)\n",
    "print(\"Test Precision Score:\", precision_score)\n",
    "recall_score = recall_score(y_test, y_pred_test)\n",
    "print(\"Test Recall Score:\", recall_score)\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b23c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "sns.heatmap(confusion_matrix,annot=True, cbar=False)\n",
    "plt.xlabel(\"true label\")\n",
    "plt.ylabel(\"predicted label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f6113",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da0e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING THE METRICS OF THE BEST MODEL\n",
    "\n",
    "metrics = pd.DataFrame({\"Accuracy\": acc,\n",
    "                            \"Precision\": precision_score,\n",
    "                            \"Recall\": recall_score,\n",
    "                            \"F1\": f1_score},index=[0])\n",
    "\n",
    "metrics\n",
    "\n",
    "metrics.T.plot.bar(title = \"Best (Logistic Regression) model metrics\", legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINTING LEARNED COEFFICIENTS (WEIGHTS) FOR EACH FEATURE IN OUR BEST MODEL (LOGISTIC REGRESSION)\n",
    "best_model_lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match features to columns\n",
    "features_dict = dict(zip(df.columns, list(best_model_lr.coef_[0])))\n",
    "features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ef089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZING FEATURE IMPORTANCE\n",
    "\n",
    "features_df = pd.DataFrame(features_dict, index=[0])\n",
    "features_df.T.plot.bar(title=\"Feature Importance\", legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC CURVE FOR THE BEST MODEL\n",
    "\n",
    "# from_estimator() = use a model to plot ROC curve on data\n",
    "\n",
    "# Plotting the curve\n",
    "RocCurveDisplay.from_estimator(estimator=best_model_lr, \n",
    "                               X=X_test, \n",
    "                               y=y_test); \n",
    "\n",
    "# Calculating AUC\n",
    "\n",
    "y_pred_proba = best_model_lr.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"AUC: {auc:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962eb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "\n",
    "# Get feature names\n",
    "num_feature_names = list(num_cols)\n",
    "cat_feature_names = list(ct.named_transformers_['onehot'].get_feature_names_out(cat_cols))\n",
    "feature_names = cat_feature_names + num_feature_names\n",
    "\n",
    "# Convert to DataFrames\n",
    "X_trainval_df = pd.DataFrame(X_trainval, columns=feature_names)\n",
    "X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "\n",
    "# # Check if those names are the same\n",
    "# print(feature_names)\n",
    "# print(X_trainval_df.columns)\n",
    "\n",
    "# Create explainer\n",
    "explainer = shap.LinearExplainer(best_model_lr, X_trainval_df)\n",
    "shap_values = explainer.shap_values(X_test_df)\n",
    "\n",
    "# SHAP summary plot\n",
    "shap.summary_plot(shap_values, X_test_df, feature_names=feature_names)\n",
    "\n",
    "# # SHAP force plot for one instance (individual explanation)\n",
    "# shap.initjs()\n",
    "# i = 0\n",
    "# shap.force_plot(explainer.expected_value, shap_values[i], X_test_df.iloc[i])\n",
    "\n",
    "# If you want explicit probability of 1 for this sample\n",
    "# pred = model.predict_proba(X_test_df.iloc[[i]])[0,1]\n",
    "# print(f\"Predicted probability for sample {i}: {pred:.3f}\")\n",
    "\n",
    "\n",
    "# # If the plot is not clear, you can list all features and their SHAP values for this sample as a table\n",
    "# sample_shap = pd.DataFrame({\n",
    "#     'Feature': X_test_df.columns,\n",
    "#     'Value': X_test_df.iloc[i].values,\n",
    "#     'SHAP': shap_values[i]\n",
    "# })\n",
    "# # Add a column for absolute SHAP values\n",
    "# sample_shap['Abs_SHAP'] = sample_shap['SHAP'].abs()\n",
    "# # Sort by absolute contribution in descending order\n",
    "# sample_shap_sorted = sample_shap.sort_values(by='Abs_SHAP', ascending=False).drop(columns='Abs_SHAP')\n",
    "\n",
    "# sample_shap_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee3352",
   "metadata": {},
   "source": [
    "SHAP Summary Plot\n",
    "\n",
    "Y-axis represents features, and most important at the top.\n",
    "Color denotes value of the feature (red = high value, blue = low value).\n",
    "\n",
    "X-axis are SHAP value for that feature. Positive SHAP value for a feature means that feature pushes the prediction higher than the baseline, i.e., toward class 1. Negative SHAP value means that feature pushes the prediction lower than the baseline, i.e., toward class 0. SHAP shows how each feature “votes” to move the prediction away from the average.\n",
    "\n",
    "\n",
    "Each dot represents one observation. Red dots are high value dots (for that feature), while blue dots are low value dots.\n",
    "A dot far to the right → the feature pushes prediction higher than the baseline (toward positive class).\n",
    "A dot far to the left → the feature pushes prediction lower than the baeline (toward negative class).\n",
    "\n",
    "Feature importance is determined by the spread of SHAP values. The bigger the spread → the more influence that feature has.\n",
    "\n",
    "SHAP Force Plot\n",
    "\n",
    "Gives plot that contains the most important features, their values and visual representations of their SHAP values ie contributions to predictions (but it is better to see SHAP values in a table).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b718699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_tabular\n",
    "\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_trainval,\n",
    "    feature_names=feature_names,\n",
    "    class_names=['No', 'Yes'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Explain a single prediction\n",
    "i = 15 # row in X_test dataset\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=X_test_df.iloc[i],\n",
    "    predict_fn=model.predict_proba,\n",
    "    num_features=10 # how many features to display\n",
    ")\n",
    "\n",
    "# Printing features and their LIME values, ie contributions\n",
    "lime_exp_list = exp.as_list()\n",
    "print(lime_exp_list)\n",
    "\n",
    "exp.show_in_notebook(show_table=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd22444",
   "metadata": {},
   "source": [
    "LIME explains a single prediction by approximating the model locally with a simple interpretable model (like a linear regression) around that sample (example, instance). It assigns LIME values to features showing how much each one contributed to increasing or decreasing the prediction for that specific instance.\n",
    "\n",
    "In the upper left corner LIME displays prediction probabilities for that specific instance.\n",
    "\n",
    "Chart gives LIME values ie contributions for each feature (values 0.09, 0.06 etc), while color represents class (positive orange, negative blue). If LIME value is orange it means that value is positive, and thus contributing to positive (1) class. If LIME value is blue it means that value is negative, and thus contributing to negative (0) class. However, chart gives only absolute values, using color to denote contribution to class. Negative values can be seen using exp.as_list().\n",
    "\n",
    "Table:\n",
    "Feature column - the name of the feature (or one-hot encoded feature).\n",
    "Value column - the value of the feature (normalized since we used scaling by StandardScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f75561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL COMPONENTS\n",
    "\n",
    "joblib.dump(imputer, \"../models/imputer.joblib\")\n",
    "joblib.dump(imputer_cat, \"../models/imputer_cat.joblib\")\n",
    "joblib.dump(sc, \"../models/sc.joblib\")\n",
    "joblib.dump(ct, \"../models/ct.joblib\")\n",
    "joblib.dump(le, \"../models/le.joblib\")\n",
    "joblib.dump(best_model_lr, \"../models/model.joblib\")\n",
    "\n",
    "print(\"Saved: model, imputers, scaler, transformer, and label encoder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
